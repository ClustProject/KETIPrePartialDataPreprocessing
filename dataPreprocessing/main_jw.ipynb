{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import json\n",
    "import MSOutlierDetection\n",
    "import MissingPatternDetection\n",
    "import Imputation\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "class partialDataProcessing():\n",
    "    def __init__(self):\n",
    "        self.columnNaNCount={}\n",
    "        self.columnNaNRatio={}\n",
    "        \n",
    "    def setData(self, data):\n",
    "        self.data = data\n",
    "        self.totalLength = len(data)\n",
    "        self.columns = data.columns\n",
    "    \n",
    "    # 옆에서 가져왔음, 수정해야함 \n",
    "    def get_preprocessed_data(self, data_raw, clean_param):\n",
    "        if clean_param['flag'] ==True:\n",
    "            from KETIPrePartialDataPreprocessing.PartialDataCleansing.definite_error_detection import min_max_limit_value\n",
    "            self.limit_min_max = min_max_limit_value.MinMaxLimitValueSet().get_data_min_max_limitSet(clean_param['data_type'])\n",
    "            preprocessed_data = MSOutlierDetection.CertainOutlierDetection().get_valid_data(data_raw, self.limit_min_max)\n",
    "            #preprocessed_data = MSOutlierDetection.uncertain_outlier_detection(preprocessed_data, column) \n",
    "            # Column Error\n",
    "        else:\n",
    "            preprocessed_data = data_raw.copy()\n",
    "        return preprocessed_data\n",
    "    \n",
    "    def dataProcessingByColumn(self, imputation_parameter):\n",
    "        #Outlier2NaN = OutlierDetection.CertainOutlierDetection()\n",
    "        clean_param={'flag':True, 'data_type':'air'}\n",
    "        self.dataWithMoreNaN = self.get_preprocessed_data(self.data, clean_param)\n",
    "        # 1. Measurement Outlier Detection Module`\n",
    "        \n",
    "        for column in self.columns:\n",
    "            column_data = self.dataWithMoreNaN[[column]]\n",
    "           \n",
    "            # 2. Missing Pattern Detection Module\n",
    "            NaNPatternCheck = MissingPatternDetection.MissingPatternDetection()\n",
    "            column_data = NaNPatternCheck.get_missing_pattern(column_data, column)\n",
    "            \n",
    "            # 3. Missing Data Imputation\n",
    "            imputation_method = imputation_parameter['imputation_method']\n",
    "            totalNanLimit = imputation_parameter['totalNanLimit']\n",
    "        \n",
    "            self.columnNaNCount[column]=self.data[column].isna().sum()\n",
    "            self.columnNaNRatio[column]=round(float(self.columnNaNCount[column]*100/self.totalLength), 2)\n",
    "            if (self.columnNaNRatio[column] < totalNanLimit):\n",
    "            # if total column NaN number is less tan limit, Impute it according to the parameter    \n",
    "                for method_set in imputation_method:\n",
    "                    # 3. Missing Data Imputation\n",
    "                    column_data = self.imputeColumnData(method_set, column_data)\n",
    "    \n",
    "    #def outlierToNaN(self, data)\n",
    "    def imputeColumnData(self, method_set, dataset):\n",
    "        min_limit = method_set['min']\n",
    "        max_limit = method_set['max']\n",
    "        method = method_set['method']\n",
    "        Imputer = Imputation.imputation_methods()\n",
    "        if method == 'mean':\n",
    "            dataset = Imputer.mean_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'median':\n",
    "            dataset = Imputer.median_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'bfill':\n",
    "            dataset = Imputer.bfill(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'ffill':    \n",
    "            dataset = Imputer.ffill(dataset,  min_limit, max_limit)\n",
    "\n",
    "        if method == 'linear':\n",
    "            dataset = Imputer.linear_interpolate(dataset,  min_limit, max_limit)\n",
    "        \n",
    "        elif method == 'time':\n",
    "            dataset = Imputer.time_interpolation(dataset,  min_limit, max_limit)\n",
    "\n",
    "        elif method == 'nearest':\n",
    "            dataset = Imputer.nearest_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'zero':\n",
    "            dataset = Imputer.zero_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'slinear':\n",
    "            dataset = Imputer.slinear_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'quadratic':\n",
    "            dataset = Imputer.quadratic_interpolate(dataset, min_limit, max_limit)\n",
    "\n",
    "        elif method == 'cubic':\n",
    "            dataset = Imputer.cubic_interpolate(dataset, min_limi, max_limit)\n",
    "    \n",
    "        elif method == 'spline':\n",
    "            dataset = Imputer.spline_interpolate(dataset,  min_limi, max_limit)\n",
    "\n",
    "        elif method == 'barycentric':\n",
    "            dataset = Imputer.barycentric_interpolate(dataset, min_limi, max_limit)\n",
    "\n",
    "        elif method == 'polynomial':\n",
    "            dataset = Imputer.polynomial_interpolate(dataset, min_limi, max_limit)\n",
    "        return dataset\n",
    "            \n",
    "        \n",
    "        \n",
    "class getData():\n",
    "    def getInfluxDB(self):\n",
    "        pass\n",
    "    \n",
    "    def getFileInput(self, file_name, time_index=\"timedate\"):\n",
    "        dataset = pd.read_csv(file_name, parse_dates=True, index_col=[time_index])\n",
    "        return dataset\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = './data_miss_original.csv'\n",
    "imputation_parameter ={\n",
    "   \"imputation_method\":[\n",
    "      {\n",
    "         \"min\":0,\n",
    "         \"max\":1,\n",
    "         \"method\":\"mean\"\n",
    "      },\n",
    "      {\n",
    "         \"min\":2,\n",
    "         \"max\":4,\n",
    "         \"method\":\"linear\"\n",
    "      },\n",
    "      {\n",
    "         \"min\":5,\n",
    "         \"max\":10,\n",
    "         \"method\":\"brits\"\n",
    "      }\n",
    "   ],\n",
    "   \"totalNanLimit\":0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getData().getFileInput(input_file, 'timedate')\n",
    "MDP = partialDataProcessing()\n",
    "MDP.setData(dataset[:10000])\n",
    "MDP.dataProcessingByColumn(imputation_parameter)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'co2', 'pm10'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-21d3b0a1aecc>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-21d3b0a1aecc>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for column in dataset.columns:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
